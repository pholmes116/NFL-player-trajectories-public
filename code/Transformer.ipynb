{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9c3e8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import statistics as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "173d05eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset element specification: (TensorSpec(shape=(4,), dtype=tf.int32, name=None), TensorSpec(shape=(100, 46), dtype=tf.float32, name=None), TensorSpec(shape=(46,), dtype=tf.float32, name=None))\n",
      "\n",
      "First 3 examples:\n",
      "\n",
      "Example 1:\n",
      "Metadata tensor: tf.Tensor([2022091809         98          0          1], shape=(4,), dtype=int32)\n",
      "Metadata values: [2022091809         98          0          1]\n",
      "Input shape: (100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (46,) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [0. 0. 0. 0. 0.]\n",
      "Target values (first 5): [0.65816665 0.45928705 0.67158335 0.41782364 0.66908336]\n",
      "\n",
      "Example 2:\n",
      "Metadata tensor: tf.Tensor([2022091809         98          0          1], shape=(4,), dtype=int32)\n",
      "Metadata values: [2022091809         98          0          1]\n",
      "Input shape: (100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (46,) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [0. 0. 0. 0. 0.]\n",
      "Target values (first 5): [0.657      0.4596623  0.67108333 0.41819888 0.6676667 ]\n",
      "\n",
      "Example 3:\n",
      "Metadata tensor: tf.Tensor([2022091809         98          0          1], shape=(4,), dtype=int32)\n",
      "Metadata values: [2022091809         98          0          1]\n",
      "Input shape: (100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (46,) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [0. 0. 0. 0. 0.]\n",
      "Target values (first 5): [0.65566665 0.46022514 0.67041665 0.41894934 0.6663333 ]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../processed_data/transformer_dataset\"\n",
    "\n",
    "# Load dataset without any transformations\n",
    "raw_ds = tf.data.Dataset.load(dataset_path)\n",
    "\n",
    "# Print dataset structure\n",
    "print(\"Dataset element specification:\", raw_ds.element_spec)\n",
    "\n",
    "# Examine first 3 examples\n",
    "print(\"\\nFirst 3 examples:\")\n",
    "for i, example in enumerate(raw_ds.take(3)):\n",
    "    # Each example contains 3 components:\n",
    "    meta_tensor = example[0]  # Metadata (gameId, playId, split_id, firstFrameId)\n",
    "    x_tensor = example[1]     # Input sequence (padded frames)\n",
    "    y_tensor = example[2]     # Target vector\n",
    "    \n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(\"Metadata tensor:\", meta_tensor)\n",
    "    print(f\"Metadata values: {meta_tensor.numpy()}\")\n",
    "    print(f\"Input shape: {x_tensor.shape} | dtype: {x_tensor.dtype}\")\n",
    "    print(f\"Target shape: {y_tensor.shape} | dtype: {y_tensor.dtype}\")\n",
    "    \n",
    "    # First 5 elements of first frame's features\n",
    "    print(\"First frame features (first 5 values):\", x_tensor[0, :5].numpy())\n",
    "    print(\"Target values (first 5):\", y_tensor[:5].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3cb29bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Count examples per split\\nsplit_counts = {\"train\": 0, \"val\": 0, \"test\": 0}\\nfor meta, *_ in raw_ds:\\n    split_id = meta[2].numpy()\\n    split_counts[\"train\" if split_id==0 else \"val\" if split_id==1 else \"test\"] += 1\\nprint(split_counts)'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Count examples per split\n",
    "split_counts = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "for meta, *_ in raw_ds:\n",
    "    split_id = meta[2].numpy()\n",
    "    split_counts[\"train\" if split_id==0 else \"val\" if split_id==1 else \"test\"] += 1\n",
    "print(split_counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8d15cc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'game_splits = {}\\nfor meta, *_ in raw_ds:\\n    game_id = meta[0].numpy()\\n    split_id = meta[2].numpy()\\n    if game_id in game_splits:\\n        assert game_splits[game_id] == split_id, f\"Game {game_id} in multiple splits!\"\\n    else:\\n        game_splits[game_id] = split_id'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"game_splits = {}\n",
    "for meta, *_ in raw_ds:\n",
    "    game_id = meta[0].numpy()\n",
    "    split_id = meta[2].numpy()\n",
    "    if game_id in game_splits:\n",
    "        assert game_splits[game_id] == split_id, f\"Game {game_id} in multiple splits!\"\n",
    "    else:\n",
    "        game_splits[game_id] = split_id\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e7706af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from collections import Counter\\nseq_lengths = []\\nfor meta, x, _ in raw_ds:\\n    seq_len = tf.math.count_nonzero(tf.reduce_any(x != 0, axis=1)).numpy()\\n    seq_lengths.append(seq_len)\\nprint(\"Sequence length distribution:\", Counter(seq_lengths))'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from collections import Counter\n",
    "seq_lengths = []\n",
    "for meta, x, _ in raw_ds:\n",
    "    seq_len = tf.math.count_nonzero(tf.reduce_any(x != 0, axis=1)).numpy()\n",
    "    seq_lengths.append(seq_len)\n",
    "print(\"Sequence length distribution:\", Counter(seq_lengths))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "37b7f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and filter based on split_id\n",
    "def filter_split(split_num):\n",
    "    def _filter(meta, x, y):\n",
    "        return tf.equal(meta[2], split_num)\n",
    "    return _filter\n",
    "\n",
    "# Split the dataset into train, val, test using the split_id\n",
    "train_ds = raw_ds.filter(filter_split(0)).shuffle(4096).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = raw_ds.filter(filter_split(1)).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = raw_ds.filter(filter_split(2)).batch(64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d276f01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 3 examples:\n",
      "\n",
      "Example 1:\n",
      "Metadata tensor: tf.Tensor(\n",
      "[[2022091100        166          0         80]\n",
      " [2022091104       2662          0          1]\n",
      " [2022091101       3287          0          1]\n",
      " [2022091200        264          0         44]\n",
      " [2022091803        592          0          1]\n",
      " [2022091805       3235          0         89]\n",
      " [2022091807        330          0         67]\n",
      " [2022091807        330          0          1]\n",
      " [2022091806       2124          0         61]\n",
      " [2022091809        695          0          1]\n",
      " [2022091200        264          0          1]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091800        338          0          1]\n",
      " [2022091807       1374          0          1]\n",
      " [2022091807        735          0          1]\n",
      " [2022091807       1241          0         90]\n",
      " [2022091100        166          0          1]\n",
      " [2022091803        365          0          1]\n",
      " [2022091102       2783          0          1]\n",
      " [2022091200        264          0          1]\n",
      " [2022091807        735          0          1]\n",
      " [2022091807       1374          0          1]\n",
      " [2022091100        166          0          1]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091101       2723          0         46]\n",
      " [2022091809         98          0          1]\n",
      " [2022091807       1374          0          1]\n",
      " [2022091100        166          0          1]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091803        365          0          1]\n",
      " [2022091109       2726          0         26]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091807        330          0          1]\n",
      " [2022091200       1550          0          1]\n",
      " [2022091102       2783          0          1]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091807        330          0         46]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091802        108          0          1]\n",
      " [2022091901       3287          0          1]\n",
      " [2022091806       2124          0         43]\n",
      " [2022091809        695          0          1]\n",
      " [2022091100        166          0         51]\n",
      " [2022091901       3287          0          1]\n",
      " [2022091101       2723          0        108]\n",
      " [2022091803       1861          0          1]\n",
      " [2022091109       2726          0          1]\n",
      " [2022091809        695          0          1]\n",
      " [2022091803        365          0          2]\n",
      " [2022091102       2783          0         62]\n",
      " [2022091807        735          0          1]\n",
      " [2022091110        149          0         21]\n",
      " [2022091200        264          0         15]\n",
      " [2022091806       2124          0         75]\n",
      " [2022091110        149          0         88]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091803       1222          0         75]\n",
      " [2022091809        695          0         25]\n",
      " [2022091805       3235          0         94]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091100        166          0         53]\n",
      " [2022091111       1038          0         37]], shape=(64, 4), dtype=int32)\n",
      "Metadata values: [[2022091100        166          0         80]\n",
      " [2022091104       2662          0          1]\n",
      " [2022091101       3287          0          1]\n",
      " [2022091200        264          0         44]\n",
      " [2022091803        592          0          1]\n",
      " [2022091805       3235          0         89]\n",
      " [2022091807        330          0         67]\n",
      " [2022091807        330          0          1]\n",
      " [2022091806       2124          0         61]\n",
      " [2022091809        695          0          1]\n",
      " [2022091200        264          0          1]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091800        338          0          1]\n",
      " [2022091807       1374          0          1]\n",
      " [2022091807        735          0          1]\n",
      " [2022091807       1241          0         90]\n",
      " [2022091100        166          0          1]\n",
      " [2022091803        365          0          1]\n",
      " [2022091102       2783          0          1]\n",
      " [2022091200        264          0          1]\n",
      " [2022091807        735          0          1]\n",
      " [2022091807       1374          0          1]\n",
      " [2022091100        166          0          1]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091101       2723          0         46]\n",
      " [2022091809         98          0          1]\n",
      " [2022091807       1374          0          1]\n",
      " [2022091100        166          0          1]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091803        365          0          1]\n",
      " [2022091109       2726          0         26]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091807        330          0          1]\n",
      " [2022091200       1550          0          1]\n",
      " [2022091102       2783          0          1]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091807        330          0         46]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091802        108          0          1]\n",
      " [2022091901       3287          0          1]\n",
      " [2022091806       2124          0         43]\n",
      " [2022091809        695          0          1]\n",
      " [2022091100        166          0         51]\n",
      " [2022091901       3287          0          1]\n",
      " [2022091101       2723          0        108]\n",
      " [2022091803       1861          0          1]\n",
      " [2022091109       2726          0          1]\n",
      " [2022091809        695          0          1]\n",
      " [2022091803        365          0          2]\n",
      " [2022091102       2783          0         62]\n",
      " [2022091807        735          0          1]\n",
      " [2022091110        149          0         21]\n",
      " [2022091200        264          0         15]\n",
      " [2022091806       2124          0         75]\n",
      " [2022091110        149          0         88]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091803       1222          0         75]\n",
      " [2022091809        695          0         25]\n",
      " [2022091805       3235          0         94]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091100        166          0         53]\n",
      " [2022091111       1038          0         37]]\n",
      "Input shape: (64, 100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (64, 46) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [[0.48441666 0.61463416 0.42766666 ... 0.50375235 0.49158335 0.55515945]\n",
      " [0.48441666 0.61463416 0.42766666 ... 0.50450283 0.49158335 0.55515945]\n",
      " [0.48441666 0.61463416 0.42758334 ... 0.5050657  0.49158335 0.55515945]\n",
      " ...\n",
      " [0.47575    0.78761727 0.453      ... 0.37729833 0.42516667 0.4686679 ]\n",
      " [0.47566667 0.793621   0.45308334 ... 0.37110695 0.42675    0.45590994]\n",
      " [0.47575    0.7998124  0.45325    ... 0.36529082 0.42858332 0.4435272 ]]\n",
      "Target values (first 5): [[ 0.47833332  0.8324578   0.45491666  0.8673546   0.4985      0.51819885\n",
      "   0.44375     0.38517824  0.4515      0.80262667  0.6810833   0.18405253\n",
      "   0.49816668  0.6765478   0.47225     0.73883677  0.60566664  0.2969981\n",
      "   0.5503333   0.44746718  0.45908332  0.8065666   0.6120833   0.41144466\n",
      "   0.6903333   0.51894933  0.60575     0.16566604  0.48683333  0.6772983\n",
      "   0.5711667   0.7532833   0.7105833   0.23864916  0.44358334  0.8078799\n",
      "   0.52141666  0.5587242   0.4985      0.85816133  0.48366666  0.48424014\n",
      "   0.5125833   0.33639774  0.495       0.40187618]\n",
      " [ 0.138       0.5585366   0.142       0.61688554  0.14266667  0.5844278\n",
      "   0.14425     0.5018762   0.14666666  0.36060038  0.17533334  0.5598499\n",
      "   0.14191666  0.20243903  0.14691667  0.79512197  0.14258334  0.53714824\n",
      "   0.17625     0.60168856  0.14158334  0.6474672   0.12475     0.64296436\n",
      "   0.105       0.5125704   0.09733333  0.3521576   0.09975     0.6326454\n",
      "   0.1095      0.7020638   0.09258334  0.22213884  0.12608333  0.54071295\n",
      "   0.12525     0.80281425  0.12741667  0.6052533   0.12833333  0.4628518\n",
      "   0.10425     0.5726079   0.13558334  0.5592871 ]\n",
      " [ 0.511       0.5270169   0.51416665  0.5575985   0.5075      0.64484054\n",
      "   0.5055      0.56360227  0.51133335  0.47542214  0.56925     0.5600375\n",
      "   0.5096667   0.58742964  0.51016665  0.50093806  0.5125      0.44840527\n",
      "   0.51666665  0.3478424   0.5108333   0.6187617   0.48541668  0.5729831\n",
      "   0.46158335  0.55253285  0.45425     0.53358346  0.43916667  0.5617261\n",
      "   0.46591666  0.32776734  0.47691667  0.52964354  0.48916668  0.6185741\n",
      "   0.48541668  0.48105067  0.42816666  0.439212    0.4685      0.67560977\n",
      "   0.48291665  0.54803     0.50233334  0.5643527 ]\n",
      " [ 0.87375     0.4414634   0.8268333   0.51350844  0.7765833   0.42739213\n",
      "   0.83358335  0.33433396  0.78491664  0.12795497  0.8545      0.3977486\n",
      "   0.7875      0.0532833   0.76383334  0.8487805   0.84258336  0.4425891\n",
      "   0.84891665  0.630394    0.84475     0.47879925  0.8269167   0.4054409\n",
      "   0.84216666  0.35797372  0.68866664  0.46866792  0.78225     0.06641651\n",
      "   0.82375     0.30300188  0.81383336  0.46885553  0.75908333  0.17842402\n",
      "   0.72658336  0.79812384  0.74766666  0.36885554  0.78508335  0.62476546\n",
      "   0.76891667  0.17467166  0.77375    -0.02270169]\n",
      " [ 0.824       0.31557223  0.822       0.42251408  0.82575     0.6005629\n",
      "   0.81875     0.5054409   0.81908333  0.6521576   0.81325     0.6771107\n",
      "   0.8193333   0.3968105   0.8204167   0.475985    0.7895      0.40581614\n",
      "   0.7895833   0.454409    0.82775     0.45046905  0.84291667  0.30262664\n",
      "   0.8419167   0.49512196  0.84108335  0.5489681   0.83783334  0.42870545\n",
      "   0.8616667   0.6626642   0.8745      0.55722326  0.8885      0.72889304\n",
      "   0.86441666  0.37861162  0.9228333   0.58536583  0.8433333   0.34615386\n",
      "   0.89675     0.41181988  0.83141667  0.44953093]]\n",
      "\n",
      "Example 2:\n",
      "Metadata tensor: tf.Tensor(\n",
      "[[2022091111       1038          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091102       2532          0         46]\n",
      " [2022091807        330          0          1]\n",
      " [2022091807        330          0         13]\n",
      " [2022091102       2783          0          1]\n",
      " [2022091110        149          0         60]\n",
      " [2022091809         98          0          1]\n",
      " [2022091803        365          0         66]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091102       2532          0          1]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091807       1241          0          1]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091807       1374          0         36]\n",
      " [2022091110        149          0         67]\n",
      " [2022091805       3235          0         79]\n",
      " [2022091100        166          0         17]\n",
      " [2022091807       1241          0         52]\n",
      " [2022091102       2532          0         51]\n",
      " [2022091110        149          0          1]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091109       1287          0          1]\n",
      " [2022091809        695          0         99]\n",
      " [2022091109       1287          0          1]\n",
      " [2022091803        365          0         53]\n",
      " [2022091101       2723          0         60]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091102       2783          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091100        166          0          1]\n",
      " [2022091100        166          0          1]\n",
      " [2022091200       1550          0          1]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091803       1222          0         40]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091807        330          0          1]\n",
      " [2022091806       2124          0         18]\n",
      " [2022091807        735          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091109       1287          0          1]\n",
      " [2022091803        365          0          1]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091805       3235          0         63]\n",
      " [2022091807       1374          0          1]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091100        166          0         59]\n",
      " [2022091111       1038          0         48]\n",
      " [2022091803        365          0         64]\n",
      " [2022091102       2783          0         32]\n",
      " [2022091803       1222          0          4]\n",
      " [2022091803        592          0          1]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091803        365          0          1]\n",
      " [2022091109       1287          0          1]\n",
      " [2022091807       1374          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091102       2532          0         45]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091803       1861          0         48]\n",
      " [2022091110        149          0          1]\n",
      " [2022091807        330          0          1]\n",
      " [2022091807        330          0         72]], shape=(64, 4), dtype=int32)\n",
      "Metadata values: [[2022091111       1038          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091102       2532          0         46]\n",
      " [2022091807        330          0          1]\n",
      " [2022091807        330          0         13]\n",
      " [2022091102       2783          0          1]\n",
      " [2022091110        149          0         60]\n",
      " [2022091809         98          0          1]\n",
      " [2022091803        365          0         66]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091102       2532          0          1]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091807       1241          0          1]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091807       1374          0         36]\n",
      " [2022091110        149          0         67]\n",
      " [2022091805       3235          0         79]\n",
      " [2022091100        166          0         17]\n",
      " [2022091807       1241          0         52]\n",
      " [2022091102       2532          0         51]\n",
      " [2022091110        149          0          1]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091109       1287          0          1]\n",
      " [2022091809        695          0         99]\n",
      " [2022091109       1287          0          1]\n",
      " [2022091803        365          0         53]\n",
      " [2022091101       2723          0         60]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091102       2783          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091100        166          0          1]\n",
      " [2022091100        166          0          1]\n",
      " [2022091200       1550          0          1]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091803       1222          0         40]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091807        330          0          1]\n",
      " [2022091806       2124          0         18]\n",
      " [2022091807        735          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091109       1287          0          1]\n",
      " [2022091803        365          0          1]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091805       3235          0         63]\n",
      " [2022091807       1374          0          1]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091100        166          0         59]\n",
      " [2022091111       1038          0         48]\n",
      " [2022091803        365          0         64]\n",
      " [2022091102       2783          0         32]\n",
      " [2022091803       1222          0          4]\n",
      " [2022091803        592          0          1]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091803        365          0          1]\n",
      " [2022091109       1287          0          1]\n",
      " [2022091807       1374          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091102       2532          0         45]\n",
      " [2022091806       2124          0          1]\n",
      " [2022091803       1861          0         48]\n",
      " [2022091110        149          0          1]\n",
      " [2022091807        330          0          1]\n",
      " [2022091807        330          0         72]]\n",
      "Input shape: (64, 100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (64, 46) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.10975    0.3347092  0.0955     ... 0.2812383  0.091      0.44221386]\n",
      " [0.10966667 0.3348968  0.09541667 ... 0.2816135  0.091      0.44221386]\n",
      " [0.10983333 0.33508444 0.095      ... 0.28198874 0.09091666 0.44221386]]\n",
      "Target values (first 5): [[ 0.111       0.3337711   0.09583333  0.4422139   0.10058333  0.41219512\n",
      "   0.098       0.52138835  0.15416667  0.43771106  0.09925     0.49287054\n",
      "   0.101       0.44446528  0.10366666  0.38761726  0.10041667  0.35234523\n",
      "   0.09875     0.4673546   0.13283333  0.44071296  0.08558334  0.35703564\n",
      "   0.08625     0.46060038  0.04966667  0.39756098  0.0845      0.42420262\n",
      "   0.049       0.4902439   0.08466667  0.38348967  0.08283333  0.49061912\n",
      "   0.08191667  0.59305817  0.08425     0.52570355  0.0425      0.43639776\n",
      "   0.07866666  0.28236398  0.09083333  0.44221386]\n",
      " [ 0.78466666  0.37110695  0.8200833   0.4262664   0.8110833   0.5628518\n",
      "   0.8139167   0.49962476  0.7899167   0.5577861   0.7894167   0.5849906\n",
      "   0.8135833   0.39962476  0.81691664  0.47317073  0.7834167   0.41894934\n",
      "   0.7859167   0.45065665  0.82566667  0.45140713  0.8409167   0.40487805\n",
      "   0.84683335  0.45797375  0.8401667   0.54183865  0.8415      0.45816135\n",
      "   0.8599167   0.53639776  0.86158335  0.48499063  0.8894167   0.4795497\n",
      "   0.8774167   0.42814258  0.88625     0.5219512   0.8436667   0.35046905\n",
      "   0.8803333   0.37373358  0.83108336  0.44953093]\n",
      " [ 0.37616667  0.4129456   0.26633334  0.4902439   0.28308332  0.43621013\n",
      "   0.35683334  0.35365853  0.30683333  0.41594747  0.39333335  0.87636024\n",
      "   0.41525     0.70075047  0.42341667 -0.01894934  0.27516666  0.44859287\n",
      "   0.2835      0.4097561   0.27416667  0.4348968   0.5290833   0.39868668\n",
      "   0.28775     0.4868668   0.28658333  0.44390243  0.36616668  0.43302065\n",
      "   0.42633334  0.68180114  0.428      -0.0054409   0.28058332  0.42138836\n",
      "   0.40733334  0.6686679   0.36291668  0.37917447  0.29991665  0.35328332\n",
      "   0.36108333  0.33864915  0.35750002  0.3521576 ]\n",
      " [ 0.2615      0.7120075   0.24925     0.50018764  0.28366667  0.56191367\n",
      "   0.24775     0.5322702   0.24691667  0.58742964  0.24741666  0.61369604\n",
      "   0.257       0.38667917  0.25416666  0.41876173  0.2475      0.678424\n",
      "   0.24316667  0.5574109   0.26375     0.4001876   0.21075     0.50150096\n",
      "   0.22941667  0.6131332   0.19633333  0.3846154   0.17725     0.76322705\n",
      "   0.228       0.6898687   0.19316667  0.6575985   0.15583333  0.28236398\n",
      "   0.23075     0.54146343  0.14983334  0.49005628  0.22883333  0.4369606\n",
      "   0.14808333  0.63302064  0.24083333  0.55834895]\n",
      " [ 0.26616666  0.4500938   0.24958333  0.49849907  0.28166667  0.55947465\n",
      "   0.24825     0.53358346  0.24733333  0.5859287   0.24783333  0.6148218\n",
      "   0.24708334  0.38517824  0.25458333  0.41894934  0.24775     0.6782364\n",
      "   0.24308333  0.5574109   0.25716665  0.33996248  0.21625     0.4915572\n",
      "   0.23325     0.612758    0.21525     0.36210132  0.16316667  0.74071294\n",
      "   0.23075     0.67542213  0.18508333  0.54971856  0.17058334  0.30281425\n",
      "   0.23366667  0.53414637  0.1515      0.47692308  0.23483333  0.43864915\n",
      "   0.14458333  0.57992494  0.24041668  0.5577861 ]]\n",
      "\n",
      "Example 3:\n",
      "Metadata tensor: tf.Tensor(\n",
      "[[2022091803        365          0          1]\n",
      " [2022091809         98          0          1]\n",
      " [2022091200        264          0          1]\n",
      " [2022091100        166          0         81]\n",
      " [2022091807        735          0         42]\n",
      " [2022091805       3235          0         83]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091800        338          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091101       3287          0          1]\n",
      " [2022091807       1241          0         76]\n",
      " [2022091110        149          0          1]\n",
      " [2022091807        330          0         40]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091110        149          0          1]\n",
      " [2022091803        365          0          1]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091809        695          0          1]\n",
      " [2022091200        264          0          1]\n",
      " [2022091101       3287          0         59]\n",
      " [2022091807       1241          0         92]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091807        330          0          1]\n",
      " [2022091809         98          0          1]\n",
      " [2022091800        338          0          1]\n",
      " [2022091109       2726          0          1]\n",
      " [2022091805       3235          0         50]\n",
      " [2022091109       1287          0         13]\n",
      " [2022091806       2124          0         74]\n",
      " [2022091809        695          0          1]\n",
      " [2022091805       3235          0         95]\n",
      " [2022091200        264          0          1]\n",
      " [2022091809        695          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091102       2532          0          1]\n",
      " [2022091809        695          0          1]\n",
      " [2022091200       1550          0          4]\n",
      " [2022091901       3287          0          1]\n",
      " [2022091111       1038          0         11]\n",
      " [2022091102       2783          0         20]\n",
      " [2022091807       1374          0          9]\n",
      " [2022091101       2723          0         98]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091102       2783          0          1]\n",
      " [2022091803        365          0         22]\n",
      " [2022091802        108          0          1]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091807        330          0          1]\n",
      " [2022091104       2662          0          1]\n",
      " [2022091809         98          0          1]\n",
      " [2022091101       3287          0         85]\n",
      " [2022091200        264          0          1]\n",
      " [2022091110        149          0         44]\n",
      " [2022091109       1287          0         36]\n",
      " [2022091800        338          0          1]\n",
      " [2022091807       1241          0         11]\n",
      " [2022091809        695          0         53]\n",
      " [2022091200        264          0          1]\n",
      " [2022091104       2662          0          1]\n",
      " [2022091803       1861          0          1]\n",
      " [2022091200        264          0          1]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091803       1222          0          1]], shape=(64, 4), dtype=int32)\n",
      "Metadata values: [[2022091803        365          0          1]\n",
      " [2022091809         98          0          1]\n",
      " [2022091200        264          0          1]\n",
      " [2022091100        166          0         81]\n",
      " [2022091807        735          0         42]\n",
      " [2022091805       3235          0         83]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091800        338          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091101       3287          0          1]\n",
      " [2022091807       1241          0         76]\n",
      " [2022091110        149          0          1]\n",
      " [2022091807        330          0         40]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091110        149          0          1]\n",
      " [2022091803        365          0          1]\n",
      " [2022091805       3235          0          1]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091809        695          0          1]\n",
      " [2022091200        264          0          1]\n",
      " [2022091101       3287          0         59]\n",
      " [2022091807       1241          0         92]\n",
      " [2022091101       2723          0          1]\n",
      " [2022091807        330          0          1]\n",
      " [2022091809         98          0          1]\n",
      " [2022091800        338          0          1]\n",
      " [2022091109       2726          0          1]\n",
      " [2022091805       3235          0         50]\n",
      " [2022091109       1287          0         13]\n",
      " [2022091806       2124          0         74]\n",
      " [2022091809        695          0          1]\n",
      " [2022091805       3235          0         95]\n",
      " [2022091200        264          0          1]\n",
      " [2022091809        695          0          1]\n",
      " [2022091803        592          0          1]\n",
      " [2022091102       2532          0          1]\n",
      " [2022091809        695          0          1]\n",
      " [2022091200       1550          0          4]\n",
      " [2022091901       3287          0          1]\n",
      " [2022091111       1038          0         11]\n",
      " [2022091102       2783          0         20]\n",
      " [2022091807       1374          0          9]\n",
      " [2022091101       2723          0         98]\n",
      " [2022091111       1038          0          1]\n",
      " [2022091102       2783          0          1]\n",
      " [2022091803        365          0         22]\n",
      " [2022091802        108          0          1]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091807        330          0          1]\n",
      " [2022091104       2662          0          1]\n",
      " [2022091809         98          0          1]\n",
      " [2022091101       3287          0         85]\n",
      " [2022091200        264          0          1]\n",
      " [2022091110        149          0         44]\n",
      " [2022091109       1287          0         36]\n",
      " [2022091800        338          0          1]\n",
      " [2022091807       1241          0         11]\n",
      " [2022091809        695          0         53]\n",
      " [2022091200        264          0          1]\n",
      " [2022091104       2662          0          1]\n",
      " [2022091803       1861          0          1]\n",
      " [2022091200        264          0          1]\n",
      " [2022091803       1222          0          1]\n",
      " [2022091803       1222          0          1]]\n",
      "Input shape: (64, 100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (64, 46) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.47991666 0.60168856 0.51375    ... 0.34727955 0.5215     0.44990617]\n",
      " [0.48133335 0.61144465 0.51383334 ... 0.34465292 0.5215     0.44990617]\n",
      " [0.48266667 0.6213884  0.5139167  ... 0.34202626 0.5215     0.44990617]]\n",
      "Target values (first 5): [[0.49133334 0.67992496 0.514      0.4251407  0.507      0.3129456\n",
      "  0.51       0.50581616 0.49683332 0.6309568  0.5100833  0.60168856\n",
      "  0.5121667  0.3932458  0.5093333  0.48067543 0.48458335 0.19174483\n",
      "  0.47875    0.45609757 0.517      0.45365855 0.5388333  0.37204504\n",
      "  0.53458333 0.40600374 0.53466666 0.5566604  0.53391665 0.46228892\n",
      "  0.53608334 0.6170732  0.5545833  0.51988745 0.55941665 0.64615387\n",
      "  0.56158334 0.42138836 0.61291665 0.5165103  0.535      0.3545966\n",
      "  0.56616664 0.32645404 0.5215833  0.4500938 ]\n",
      " [0.6128333  0.65741086 0.60425    0.7333959  0.572      0.37917447\n",
      "  0.667      0.46247655 0.60366666 0.7530957  0.64816666 0.7181989\n",
      "  0.626      0.57654786 0.60866666 0.754409   0.61941665 0.5988743\n",
      "  0.6156667  0.541651   0.65991664 0.72232646 0.5649167  0.30018762\n",
      "  0.54983336 0.75797373 0.6350833  0.5793621  0.6535     0.6891182\n",
      "  0.5845     0.47448406 0.60866666 0.5489681  0.488      0.430394\n",
      "  0.63416666 0.68611634 0.6246667  0.7013133  0.5775     0.6116323\n",
      "  0.60425    0.74277675 0.6479167  0.72307694]\n",
      " [0.83783334 0.44465292 0.8365     0.49737337 0.8383333  0.5307692\n",
      "  0.83958334 0.38836774 0.83491665 0.27317074 0.83566666 0.41894934\n",
      "  0.84641665 0.5553471  0.84008336 0.64634144 0.8293333  0.44427767\n",
      "  0.8850833  0.4425891  0.8361667  0.4709193  0.815      0.4489681\n",
      "  0.8165     0.3945591  0.74591666 0.5641651  0.74525    0.37804878\n",
      "  0.8250833  0.3251407  0.82       0.52570355 0.80508333 0.4348968\n",
      "  0.78358334 0.6780488  0.78641665 0.49362102 0.81691664 0.58517826\n",
      "  0.8099167  0.27485928 0.8243333  0.44765478]\n",
      " [0.47891667 0.8369606  0.45533332 0.8750469  0.5005     0.51125705\n",
      "  0.44641668 0.37392122 0.45008335 0.8084428  0.68808335 0.17954972\n",
      "  0.49883333 0.68217635 0.47233334 0.7429643  0.60725    0.2923077\n",
      "  0.5510833  0.43245777 0.45841667 0.81125706 0.6106667  0.4\n",
      "  0.6928333  0.5110694  0.606      0.16604127 0.48791668 0.67560977\n",
      "  0.573      0.75140715 0.7155     0.23039399 0.441      0.81031895\n",
      "  0.52166665 0.5469043  0.50091666 0.86228895 0.48525    0.47373357\n",
      "  0.50883335 0.33283302 0.51225    0.39756098]\n",
      " [0.54541665 0.43076923 0.55508333 0.39887428 0.5994167  0.62664163\n",
      "  0.5574167  0.5125704  0.47758332 0.5769231  0.54775    0.56360227\n",
      "  0.56175    0.567167   0.52916664 0.41163227 0.5114167  0.28292683\n",
      "  0.554      0.42964354 0.5208333  0.3716698  0.55558336 0.5290807\n",
      "  0.56025    0.5893058  0.47016665 0.5739212  0.5913333  0.4868668\n",
      "  0.54875    0.41444653 0.5171667  0.3641651  0.50208336 0.2968105\n",
      "  0.5499167  0.43189493 0.4205     0.5140713  0.54525    0.5876173\n",
      "  0.52425    0.41144466 0.5438334  0.43264538]]\n"
     ]
    }
   ],
   "source": [
    "# Examine first 3 examples\n",
    "print(\"\\nFirst 3 examples:\")\n",
    "for i, example in enumerate(train_ds.take(3)):\n",
    "    # Each example contains 3 components:\n",
    "    meta_tensor = example[0]  # Metadata (gameId, playId, split_id, firstFrameId)\n",
    "    x_tensor = example[1]     # Input sequence (padded frames)\n",
    "    y_tensor = example[2]     # Target vector\n",
    "    \n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(\"Metadata tensor:\", meta_tensor)\n",
    "    print(f\"Metadata values: {meta_tensor.numpy()}\")\n",
    "    print(f\"Input shape: {x_tensor.shape} | dtype: {x_tensor.dtype}\")\n",
    "    print(f\"Target shape: {y_tensor.shape} | dtype: {y_tensor.dtype}\")\n",
    "    \n",
    "    # First 5 elements of first frame's features\n",
    "    print(\"First frame features (first 5 values):\", x_tensor[0, :-5].numpy())\n",
    "    print(\"Target values (first 5):\", y_tensor[:5].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "117a222c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cardinality: 592871\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset cardinality:\",\n",
    "      tf.data.experimental.cardinality(raw_ds).numpy())   # should now print a number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cd6089c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: (64, 100, 46)\n",
      "y_batch shape: (64, 46)\n",
      "x_batch shape: (64, 100, 46)\n",
      "y_batch shape: (64, 46)\n",
      "x_batch shape: (64, 100, 46)\n",
      "y_batch shape: (64, 46)\n"
     ]
    }
   ],
   "source": [
    "def drop_meta(meta, x, y):\n",
    "    return x, y\n",
    "\n",
    "train_ds = (raw_ds\n",
    "            .filter(filter_split(0))\n",
    "            .map(drop_meta, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .shuffle(4096)\n",
    "            .batch(64)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "val_ds   = (raw_ds\n",
    "            .filter(filter_split(1))\n",
    "            .map(drop_meta, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(64)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "test_ds  = (raw_ds\n",
    "            .filter(filter_split(2))\n",
    "            .map(drop_meta, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(64)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "# Take one batch from the dataset\n",
    "for x_batch, y_batch in train_ds.take(1):\n",
    "    print(\"x_batch shape:\", x_batch.shape)\n",
    "    print(\"y_batch shape:\", y_batch.shape)\n",
    "\n",
    "for x_batch, y_batch in val_ds.take(1):\n",
    "    print(\"x_batch shape:\", x_batch.shape)\n",
    "    print(\"y_batch shape:\", y_batch.shape)\n",
    "\n",
    "for x_batch, y_batch in test_ds.take(1):\n",
    "    print(\"x_batch shape:\", x_batch.shape)\n",
    "    print(\"y_batch shape:\", y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b50d2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "NUM_FEATS = 46          # x,y for 23 entities\n",
    "MAX_LEN  = 100          # same value you used in dataset builder\n",
    "D_MODEL  = 128          # transformer hidden size\n",
    "N_HEADS  = 4\n",
    "N_LAYERS = 4\n",
    "D_FF     = 512\n",
    "DROPOUT  = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a069e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔═══════════════════╗\n",
    "# ║ 2. Positional enc ║  (learnable 1‑D embedding)\n",
    "# ╚═══════════════════╝\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super().__init__()\n",
    "        self.pos_emb = self.add_weight(\n",
    "            name=\"pos_emb\",\n",
    "            shape=(max_len, d_model),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.pos_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1372b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔═══════════════════════════╗\n",
    "# ║ 3. Padding‑mask function  ║\n",
    "# ╚═══════════════════════════╝\n",
    "class PaddingMask(layers.Layer):\n",
    "    def call(self, x):\n",
    "        # x:  (B, T, F) — zero‐padded on the left\n",
    "        pad = tf.reduce_all(tf.equal(x, 0.0), axis=-1)      # → (B, T)\n",
    "        # reshape to (B, 1, 1, T) for MultiHeadAttention\n",
    "        return pad[:, tf.newaxis, tf.newaxis, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3e0ec51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔════════════════════════╗\n",
    "# ║ 4. Transformer encoder ║\n",
    "# ╚════════════════════════╝\n",
    "def transformer_block(d_model, n_heads, d_ff, dropout):\n",
    "    inputs   = layers.Input(shape=(None, d_model))\n",
    "    padding  = layers.Input(shape=(1,1,None), dtype=tf.bool)  # mask\n",
    "\n",
    "    x = layers.MultiHeadAttention(\n",
    "        num_heads=n_heads, key_dim=d_model//n_heads, dropout=dropout\n",
    "    )(inputs, inputs, attention_mask=padding)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs + x)\n",
    "\n",
    "    y = layers.Dense(d_ff, activation=\"relu\")(x)\n",
    "    y = layers.Dense(d_model)(y)\n",
    "    y = layers.Dropout(dropout)(y)\n",
    "    y = layers.LayerNormalization(epsilon=1e-6)(x + y)\n",
    "\n",
    "    return keras.Model([inputs, padding], y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "22063c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"NFL_Frame_Predictor\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 100, 46)]    0           []                               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 100, 128)     6016        ['sequence[0][0]']               \n",
      "                                                                                                  \n",
      " positional_encoding_3 (Positio  (None, 100, 128)    12800       ['dense_27[0][0]']               \n",
      " nalEncoding)                                                                                     \n",
      "                                                                                                  \n",
      " padding_mask_3 (PaddingMask)   (None, 1, 1, 100)    0           ['sequence[0][0]']               \n",
      "                                                                                                  \n",
      " model_12 (Functional)          (None, None, 128)    198272      ['positional_encoding_3[0][0]',  \n",
      "                                                                  'padding_mask_3[0][0]']         \n",
      "                                                                                                  \n",
      " model_13 (Functional)          (None, None, 128)    198272      ['model_12[0][0]',               \n",
      "                                                                  'padding_mask_3[0][0]']         \n",
      "                                                                                                  \n",
      " model_14 (Functional)          (None, None, 128)    198272      ['model_13[0][0]',               \n",
      "                                                                  'padding_mask_3[0][0]']         \n",
      "                                                                                                  \n",
      " model_15 (Functional)          (None, None, 128)    198272      ['model_14[0][0]',               \n",
      "                                                                  'padding_mask_3[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 128)          0           ['model_15[0][0]']               \n",
      "                                                                                                  \n",
      " pred_xy (Dense)                (None, 46)           5934        ['lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 817,838\n",
      "Trainable params: 817,838\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ╔════════════════════════════════╗\n",
    "# ║ 5. End‑to‑end prediction model ║\n",
    "# ╚════════════════════════════════╝\n",
    "def build_model(\n",
    "    num_feats=NUM_FEATS,\n",
    "    max_len=MAX_LEN,\n",
    "    d_model=D_MODEL,\n",
    "    n_heads=N_HEADS,\n",
    "    n_layers=N_LAYERS,\n",
    "    d_ff=D_FF,\n",
    "    dropout=DROPOUT,\n",
    "):\n",
    "    seq_in  = layers.Input(shape=(max_len, num_feats), name=\"sequence\")   # (B,T,F)\n",
    "\n",
    "    # Linear projection to d_model\n",
    "    x = layers.Dense(d_model)(seq_in)\n",
    "\n",
    "    # Add learnable positional encodings\n",
    "    x = PositionalEncoding(max_len, d_model)(x)\n",
    "\n",
    "    # Build padding mask once\n",
    "    pad_mask = PaddingMask()(seq_in)\n",
    "\n",
    "    # Stack encoder layers\n",
    "    for _ in range(n_layers):\n",
    "        x = transformer_block(d_model, n_heads, d_ff, dropout)([x, pad_mask])\n",
    "\n",
    "    # We need the hidden state that corresponds to *frame t* (the last row)\n",
    "    # – that is always index -1 thanks to left padding.\n",
    "    h_t = layers.Lambda(lambda t: t[:, -1])(x)          # (B, D)\n",
    "\n",
    "    # Regress the 46 co‑ordinates\n",
    "    out = layers.Dense(num_feats, name=\"pred_xy\")(h_t)\n",
    "\n",
    "    return keras.Model(seq_in, out, name=\"NFL_Frame_Predictor\")\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60621355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "      6/Unknown - 11s 815ms/step - loss: 0.1442 - mean_absolute_error: 0.3017"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# ── 4)  Fit – stop early, save weights each epoch ────────────────────\u001b[39;00m\n\u001b[0;32m     35\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m   \u001b[38;5;66;03m# high ceiling; early-stop decides real count\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# optional: evaluate on test set after training\u001b[39;00m\n\u001b[0;32m     45\u001b[0m test_loss, test_mae \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_ds, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\miniconda3\\envs\\NFL_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\miniconda3\\envs\\NFL_env\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\sebas\\miniconda3\\envs\\NFL_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\miniconda3\\envs\\NFL_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\miniconda3\\envs\\NFL_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\sebas\\miniconda3\\envs\\NFL_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\miniconda3\\envs\\NFL_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\sebas\\miniconda3\\envs\\NFL_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\miniconda3\\envs\\NFL_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ╔════════════════════╗\n",
    "# ║ 6. Compile & train ║\n",
    "# ╚════════════════════╝\n",
    "\n",
    "# ── 1)  Make sure we have a place to put checkpoints ─────────────────\n",
    "WEIGHT_DIR = Path(\"../weights\")\n",
    "WEIGHT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=(WEIGHT_DIR /\n",
    "              \"epoch_{epoch:03d}-val{val_loss:.4f}.keras\").as_posix(),\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=False,      # save every epoch → “periodic” archive\n",
    "    save_weights_only=True,    # just the weights, not optimizer state\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# ── 2)  Early-stopping ───────────────────────────────────────────────\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# ── 3)  Compile the model ────────────────────────────────────────────\n",
    "LR = 1e-4\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(LR),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    ")\n",
    "\n",
    "# ── 4)  Fit – stop early, save weights each epoch ────────────────────\n",
    "EPOCHS = 5   # high ceiling; early-stop decides real count\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stop, ckpt_cb],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# optional: evaluate on test set after training\n",
    "test_loss, test_mae = model.evaluate(test_ds, verbose=1)\n",
    "print(f\"\\n✅  Test MSE: {test_loss:.5f}   |   Test MAE: {test_mae:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔═══════════════╗\n",
    "# ║ 7. Evaluation ║\n",
    "# ╚═══════════════╝\n",
    "# Simple end‑to‑end evaluation on a held‑out batch\n",
    "for X_batch, y_batch in val_ds.take(1):\n",
    "    y_pred = model(X_batch)\n",
    "    mse = tf.reduce_mean(tf.square(y_pred - y_batch))\n",
    "    print(\"Validation MSE (batch):\", mse.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NFL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
