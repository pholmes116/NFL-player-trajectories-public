{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c3e8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30cec3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using GPU: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        print(f\"✅ Using GPU: {gpus[0].name}\")\n",
    "        # Set mixed precision policy\n",
    "        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    except RuntimeError as e:\n",
    "        print(\"Failed to set GPU memory growth:\", e)\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")\n",
    "\n",
    "# Set logging\n",
    "tf.debugging.set_log_device_placement(False) # Set it to True to make sure the GPU is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173d05eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745605334.860878   64744 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset element specification: (TensorSpec(shape=(4,), dtype=tf.int32, name=None), TensorSpec(shape=(100, 46), dtype=tf.float32, name=None), TensorSpec(shape=(46,), dtype=tf.float32, name=None))\n",
      "\n",
      "First 3 examples:\n",
      "\n",
      "Example 1:\n",
      "Metadata tensor: tf.Tensor([2022091109       2481          2          1], shape=(4,), dtype=int32)\n",
      "Metadata values: [2022091109       2481          2          1]\n",
      "Input shape: (100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (46,) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [0. 0. 0. 0. 0.]\n",
      "Target values (first 5): [0.14491667 0.6643527  0.14858334 0.30731708 0.12266666]\n",
      "\n",
      "Example 2:\n",
      "Metadata tensor: tf.Tensor([2022091109       2481          2          1], shape=(4,), dtype=int32)\n",
      "Metadata values: [2022091109       2481          2          1]\n",
      "Input shape: (100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (46,) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [0. 0. 0. 0. 0.]\n",
      "Target values (first 5): [0.14316666 0.6733583  0.14766666 0.30450282 0.12191667]\n",
      "\n",
      "Example 3:\n",
      "Metadata tensor: tf.Tensor([2022091109       2481          2          1], shape=(4,), dtype=int32)\n",
      "Metadata values: [2022091109       2481          2          1]\n",
      "Input shape: (100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (46,) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [0. 0. 0. 0. 0.]\n",
      "Target values (first 5): [0.14141667 0.68217635 0.14675    0.3018762  0.12116667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 19:22:15.203303: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../processed_data/transformer_dataset\"\n",
    "\n",
    "# Load dataset without any transformations\n",
    "raw_ds = tf.data.Dataset.load(dataset_path)\n",
    "\n",
    "# Print dataset structure\n",
    "print(\"Dataset element specification:\", raw_ds.element_spec)\n",
    "\n",
    "# Examine first 3 examples\n",
    "print(\"\\nFirst 3 examples:\")\n",
    "for i, example in enumerate(raw_ds.take(3)):\n",
    "    # Each example contains 3 components:\n",
    "    meta_tensor = example[0]  # Metadata (gameId, playId, split_id, firstFrameId)\n",
    "    x_tensor = example[1]     # Input sequence (padded frames)\n",
    "    y_tensor = example[2]     # Target vector\n",
    "    \n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(\"Metadata tensor:\", meta_tensor)\n",
    "    print(f\"Metadata values: {meta_tensor.numpy()}\")\n",
    "    print(f\"Input shape: {x_tensor.shape} | dtype: {x_tensor.dtype}\")\n",
    "    print(f\"Target shape: {y_tensor.shape} | dtype: {y_tensor.dtype}\")\n",
    "    \n",
    "    # First 5 elements of first frame's features\n",
    "    print(\"First frame features (first 5 values):\", x_tensor[0, :5].numpy())\n",
    "    print(\"Target values (first 5):\", y_tensor[:5].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb29bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Count examples per split\\nsplit_counts = {\"train\": 0, \"val\": 0, \"test\": 0}\\nfor meta, *_ in raw_ds:\\n    split_id = meta[2].numpy()\\n    split_counts[\"train\" if split_id==0 else \"val\" if split_id==1 else \"test\"] += 1\\nprint(split_counts)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Count examples per split\n",
    "split_counts = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "for meta, *_ in raw_ds:\n",
    "    split_id = meta[2].numpy()\n",
    "    split_counts[\"train\" if split_id==0 else \"val\" if split_id==1 else \"test\"] += 1\n",
    "print(split_counts)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d15cc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'game_splits = {}\\nfor meta, *_ in raw_ds:\\n    game_id = meta[0].numpy()\\n    split_id = meta[2].numpy()\\n    if game_id in game_splits:\\n        assert game_splits[game_id] == split_id, f\"Game {game_id} in multiple splits!\"\\n    else:\\n        game_splits[game_id] = split_id'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"game_splits = {}\n",
    "for meta, *_ in raw_ds:\n",
    "    game_id = meta[0].numpy()\n",
    "    split_id = meta[2].numpy()\n",
    "    if game_id in game_splits:\n",
    "        assert game_splits[game_id] == split_id, f\"Game {game_id} in multiple splits!\"\n",
    "    else:\n",
    "        game_splits[game_id] = split_id\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7706af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from collections import Counter\\nseq_lengths = []\\nfor meta, x, _ in raw_ds:\\n    seq_len = tf.math.count_nonzero(tf.reduce_any(x != 0, axis=1)).numpy()\\n    seq_lengths.append(seq_len)\\nprint(\"Sequence length distribution:\", Counter(seq_lengths))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from collections import Counter\n",
    "seq_lengths = []\n",
    "for meta, x, _ in raw_ds:\n",
    "    seq_len = tf.math.count_nonzero(tf.reduce_any(x != 0, axis=1)).numpy()\n",
    "    seq_lengths.append(seq_len)\n",
    "print(\"Sequence length distribution:\", Counter(seq_lengths))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37b7f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and filter based on split_id\n",
    "def filter_split(split_num):\n",
    "    def _filter(meta, x, y):\n",
    "        return tf.equal(meta[2], split_num)\n",
    "    return _filter\n",
    "\n",
    "# Split the dataset into train, val, test using the split_id\n",
    "train_ds = raw_ds.filter(filter_split(0)).shuffle(4096).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = raw_ds.filter(filter_split(1)).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = raw_ds.filter(filter_split(2)).batch(64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d276f01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 3 examples:\n",
      "\n",
      "Example 1:\n",
      "Metadata tensor: tf.Tensor(\n",
      "[[2022091806       2905          0          5]\n",
      " [2022091808        631          0         66]\n",
      " [2022091901       1290          0          1]\n",
      " [2022091806       3030          0          2]\n",
      " [2022091112       2886          0         67]\n",
      " [2022091112       2886          0         55]\n",
      " [2022091901       3088          0         12]\n",
      " [2022091112       2886          0          1]\n",
      " [2022091811        835          0         12]\n",
      " [2022091102        942          0          1]\n",
      " [2022091500        257          0         20]\n",
      " [2022091104       4372          0          1]\n",
      " [2022091104       3754          0          1]\n",
      " [2022091806       2905          0          1]\n",
      " [2022091102        942          0         33]\n",
      " [2022091901       1290          0          1]\n",
      " [2022091901       3088          0         10]\n",
      " [2022091110       1232          0          1]\n",
      " [2022091110       3821          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091800       2682          0          1]\n",
      " [2022091806       3030          0          1]\n",
      " [2022091112       2886          0          1]\n",
      " [2022090800        646          0          1]\n",
      " [2022091112       1613          0        125]\n",
      " [2022091102       3652          0          1]\n",
      " [2022091901       1290          0          1]\n",
      " [2022091102        942          0          1]\n",
      " [2022091901       1290          0         48]\n",
      " [2022091104       3754          0         79]\n",
      " [2022091812       3347          0          1]\n",
      " [2022091805       2634          0         22]\n",
      " [2022091811        835          0          1]\n",
      " [2022091112       2886          0         52]\n",
      " [2022091800       2682          0          8]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091800       2682          0          1]\n",
      " [2022091808       2622          0          1]\n",
      " [2022091102        942          0          1]\n",
      " [2022091110       1290          0         74]\n",
      " [2022091104       3754          0         42]\n",
      " [2022091901       1290          0          1]\n",
      " [2022091806       2905          0         14]\n",
      " [2022091110       1232          0         92]\n",
      " [2022091806       2905          0          1]\n",
      " [2022090800        646          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091110       1232          0          1]\n",
      " [2022091104       4372          0          1]\n",
      " [2022091808        631          0          1]\n",
      " [2022091804       3308          0          1]\n",
      " [2022091110       1290          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091110       3821          0          1]\n",
      " [2022091805       2634          0          1]\n",
      " [2022091104       3754          0          1]\n",
      " [2022091806       3030          0          1]\n",
      " [2022091901       3088          0          1]\n",
      " [2022091901       3088          0          1]\n",
      " [2022091808        631          0         22]\n",
      " [2022091102        942          0          1]\n",
      " [2022091500       3090          0         78]\n",
      " [2022091500       3090          0         80]], shape=(64, 4), dtype=int32)\n",
      "Metadata values: [[2022091806       2905          0          5]\n",
      " [2022091808        631          0         66]\n",
      " [2022091901       1290          0          1]\n",
      " [2022091806       3030          0          2]\n",
      " [2022091112       2886          0         67]\n",
      " [2022091112       2886          0         55]\n",
      " [2022091901       3088          0         12]\n",
      " [2022091112       2886          0          1]\n",
      " [2022091811        835          0         12]\n",
      " [2022091102        942          0          1]\n",
      " [2022091500        257          0         20]\n",
      " [2022091104       4372          0          1]\n",
      " [2022091104       3754          0          1]\n",
      " [2022091806       2905          0          1]\n",
      " [2022091102        942          0         33]\n",
      " [2022091901       1290          0          1]\n",
      " [2022091901       3088          0         10]\n",
      " [2022091110       1232          0          1]\n",
      " [2022091110       3821          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091800       2682          0          1]\n",
      " [2022091806       3030          0          1]\n",
      " [2022091112       2886          0          1]\n",
      " [2022090800        646          0          1]\n",
      " [2022091112       1613          0        125]\n",
      " [2022091102       3652          0          1]\n",
      " [2022091901       1290          0          1]\n",
      " [2022091102        942          0          1]\n",
      " [2022091901       1290          0         48]\n",
      " [2022091104       3754          0         79]\n",
      " [2022091812       3347          0          1]\n",
      " [2022091805       2634          0         22]\n",
      " [2022091811        835          0          1]\n",
      " [2022091112       2886          0         52]\n",
      " [2022091800       2682          0          8]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091800       2682          0          1]\n",
      " [2022091808       2622          0          1]\n",
      " [2022091102        942          0          1]\n",
      " [2022091110       1290          0         74]\n",
      " [2022091104       3754          0         42]\n",
      " [2022091901       1290          0          1]\n",
      " [2022091806       2905          0         14]\n",
      " [2022091110       1232          0         92]\n",
      " [2022091806       2905          0          1]\n",
      " [2022090800        646          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091110       1232          0          1]\n",
      " [2022091104       4372          0          1]\n",
      " [2022091808        631          0          1]\n",
      " [2022091804       3308          0          1]\n",
      " [2022091110       1290          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091110       3821          0          1]\n",
      " [2022091805       2634          0          1]\n",
      " [2022091104       3754          0          1]\n",
      " [2022091806       3030          0          1]\n",
      " [2022091901       3088          0          1]\n",
      " [2022091901       3088          0          1]\n",
      " [2022091808        631          0         22]\n",
      " [2022091102        942          0          1]\n",
      " [2022091500       3090          0         78]\n",
      " [2022091500       3090          0         80]]\n",
      "Input shape: (64, 100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (64, 46) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [[0.22558333 0.42251408 0.20575    ... 0.61932456 0.17441668 0.44821763]\n",
      " [0.22525    0.42439026 0.20416667 ... 0.6228893  0.17441668 0.44821763]\n",
      " [0.22491667 0.4260788  0.20258333 ... 0.62682927 0.17441668 0.44803   ]\n",
      " ...\n",
      " [0.20966667 0.44390243 0.18141666 ... 0.84183866 0.18341666 0.4433396 ]\n",
      " [0.20975    0.44390243 0.181      ... 0.8420263  0.188      0.4435272 ]\n",
      " [0.20983334 0.44371483 0.18025    ... 0.84221387 0.19325    0.4435272 ]]\n",
      "Target values (first 5): [[0.2105     0.44090056 0.17141667 0.44634145 0.17608333 0.46041277\n",
      "  0.17683333 0.41163227 0.16675    0.21350844 0.17308334 0.6407129\n",
      "  0.17583333 0.37973735 0.18191667 0.4915572  0.18258333 0.36472794\n",
      "  0.17058334 0.8341463  0.20816667 0.46022514 0.10375    0.34390244\n",
      "  0.168      0.45816135 0.10425    0.5628518  0.16933334 0.40469044\n",
      "  0.11991667 0.21388368 0.17483333 0.3476548  0.14116667 0.45722327\n",
      "  0.13583334 0.3891182  0.17058334 0.49699813 0.11891667 0.6690431\n",
      "  0.15425    0.843152   0.2105     0.43846154]\n",
      " [0.25433335 0.50168854 0.28733334 0.5574109  0.24616666 0.5606004\n",
      "  0.25283334 0.6099437  0.24991667 0.6739212  0.28733334 0.61500937\n",
      "  0.25683334 0.16904315 0.24833333 0.3163227  0.2575     0.42701688\n",
      "  0.25266665 0.52889305 0.25175    0.5846154  0.14066666 0.5217636\n",
      "  0.23625    0.61069417 0.15066667 0.4208255  0.23183334 0.44878048\n",
      "  0.23583333 0.5011257  0.23491667 0.57560974 0.19483334 0.6878049\n",
      "  0.23441666 0.53789866 0.22966667 0.7114447  0.19541667 0.32964352\n",
      "  0.22958334 0.17579737 0.24133332 0.5602251 ]\n",
      " [0.7895     0.4422139  0.7975     0.50525326 0.79425    0.47467166\n",
      "  0.78525    0.18499061 0.79541665 0.38630393 0.798      0.6564728\n",
      "  0.828      0.40056285 0.8264167  0.43996248 0.7923333  0.7814259\n",
      "  0.79408336 0.41801125 0.79975    0.36341465 0.72758335 0.7799249\n",
      "  0.68325    0.33564728 0.7424167  0.42814258 0.7735     0.5699812\n",
      "  0.77283335 0.3260788  0.77316666 0.4902439  0.7723333  0.39756098\n",
      "  0.77383333 0.44183865 0.7406667  0.62401503 0.7435833  0.20168856\n",
      "  0.6810833  0.65384614 0.78608334 0.44315198]\n",
      " [0.6016667  0.3183865  0.6013333  0.44296435 0.596      0.50712943\n",
      "  0.60791665 0.58780485 0.6015     0.5589118  0.60258335 0.6467167\n",
      "  0.61025    0.28217635 0.59933335 0.5307692  0.63491666 0.5\n",
      "  0.63708335 0.5347092  0.5994167  0.4709193  0.5850833  0.52251405\n",
      "  0.58425    0.45609757 0.54691666 0.4684803  0.58683336 0.5726079\n",
      "  0.53025    0.7020638  0.5746667  0.30300188 0.48733333 0.37917447\n",
      "  0.50383335 0.60787994 0.5618333  0.25403377 0.5854167  0.6210131\n",
      "  0.585      0.38330206 0.59291667 0.50600374]\n",
      " [0.35941666 0.55947465 0.40808332 0.19043152 0.36925    0.57954973\n",
      "  0.40425    0.26716697 0.40425    0.5739212  0.39625    0.6159475\n",
      "  0.42016667 0.7258912  0.38933334 0.63189495 0.37275    0.30619135\n",
      "  0.391      0.6816135  0.40641665 0.58780485 0.39641666 0.6953096\n",
      "  0.45175    0.36022514 0.40166667 0.6206379  0.395      0.6433396\n",
      "  0.40383333 0.487242   0.41066667 0.5771107  0.44641668 0.27073172\n",
      "  0.46958333 0.74071294 0.39575    0.5118199  0.5215833  0.5990619\n",
      "  0.48416665 0.21125704 0.36941668 0.5833021 ]]\n",
      "\n",
      "Example 2:\n",
      "Metadata tensor: tf.Tensor(\n",
      "[[2022091112       2886          0          1]\n",
      " [2022091500        257          0         47]\n",
      " [2022091800       2682          0          1]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091808        631          0        128]\n",
      " [2022091806       2905          0          1]\n",
      " [2022091500       3090          0          1]\n",
      " [2022091110       1232          0         25]\n",
      " [2022091811        835          0         92]\n",
      " [2022091500        257          0         29]\n",
      " [2022091104       4372          0         57]\n",
      " [2022091112       1613          0         88]\n",
      " [2022091102       3652          0          1]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091104       3754          0          9]\n",
      " [2022091110       1232          0          9]\n",
      " [2022091901       1290          0          1]\n",
      " [2022090800        646          0         61]\n",
      " [2022091500       3090          0          1]\n",
      " [2022091500        257          0         16]\n",
      " [2022091805       2634          0          1]\n",
      " [2022091801        218          0          1]\n",
      " [2022090800        646          0          1]\n",
      " [2022090800        646          0          1]\n",
      " [2022091808        631          0          1]\n",
      " [2022091102       3652          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091500       3090          0         25]\n",
      " [2022091801        218          0          1]\n",
      " [2022091110       1539          0          1]\n",
      " [2022091110       1290          0          1]\n",
      " [2022091110       1232          0          1]\n",
      " [2022091112       1613          0          1]\n",
      " [2022091808        631          0          3]\n",
      " [2022091500       2046          0          1]\n",
      " [2022090800        646          0         13]\n",
      " [2022091806       3030          0        104]\n",
      " [2022091808        631          0         15]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091112       2886          0         41]\n",
      " [2022091812       3347          0          1]\n",
      " [2022091110       1232          0         60]\n",
      " [2022091110       1232          0         75]\n",
      " [2022091110       1232          0         18]\n",
      " [2022091104       4372          0          1]\n",
      " [2022091806       2905          0          1]\n",
      " [2022091811        835          0         82]\n",
      " [2022091104       3754          0         54]\n",
      " [2022091806       2905          0         23]\n",
      " [2022091808        631          0          1]\n",
      " [2022091800       2682          0          1]\n",
      " [2022091110       1232          0          1]\n",
      " [2022091102        942          0          1]\n",
      " [2022091104       3754          0         58]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091804       3308          0         15]\n",
      " [2022091805       2634          0          1]\n",
      " [2022091808        631          0          1]\n",
      " [2022091808        631          0         74]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091110       1290          0         75]\n",
      " [2022091110       3821          0          1]\n",
      " [2022091102       3652          0          1]], shape=(64, 4), dtype=int32)\n",
      "Metadata values: [[2022091112       2886          0          1]\n",
      " [2022091500        257          0         47]\n",
      " [2022091800       2682          0          1]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091808        631          0        128]\n",
      " [2022091806       2905          0          1]\n",
      " [2022091500       3090          0          1]\n",
      " [2022091110       1232          0         25]\n",
      " [2022091811        835          0         92]\n",
      " [2022091500        257          0         29]\n",
      " [2022091104       4372          0         57]\n",
      " [2022091112       1613          0         88]\n",
      " [2022091102       3652          0          1]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091104       3754          0          9]\n",
      " [2022091110       1232          0          9]\n",
      " [2022091901       1290          0          1]\n",
      " [2022090800        646          0         61]\n",
      " [2022091500       3090          0          1]\n",
      " [2022091500        257          0         16]\n",
      " [2022091805       2634          0          1]\n",
      " [2022091801        218          0          1]\n",
      " [2022090800        646          0          1]\n",
      " [2022090800        646          0          1]\n",
      " [2022091808        631          0          1]\n",
      " [2022091102       3652          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091500       3090          0         25]\n",
      " [2022091801        218          0          1]\n",
      " [2022091110       1539          0          1]\n",
      " [2022091110       1290          0          1]\n",
      " [2022091110       1232          0          1]\n",
      " [2022091112       1613          0          1]\n",
      " [2022091808        631          0          3]\n",
      " [2022091500       2046          0          1]\n",
      " [2022090800        646          0         13]\n",
      " [2022091806       3030          0        104]\n",
      " [2022091808        631          0         15]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091112       2886          0         41]\n",
      " [2022091812       3347          0          1]\n",
      " [2022091110       1232          0         60]\n",
      " [2022091110       1232          0         75]\n",
      " [2022091110       1232          0         18]\n",
      " [2022091104       4372          0          1]\n",
      " [2022091806       2905          0          1]\n",
      " [2022091811        835          0         82]\n",
      " [2022091104       3754          0         54]\n",
      " [2022091806       2905          0         23]\n",
      " [2022091808        631          0          1]\n",
      " [2022091800       2682          0          1]\n",
      " [2022091110       1232          0          1]\n",
      " [2022091102        942          0          1]\n",
      " [2022091104       3754          0         58]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091804       3308          0         15]\n",
      " [2022091805       2634          0          1]\n",
      " [2022091808        631          0          1]\n",
      " [2022091808        631          0         74]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091110       1290          0         75]\n",
      " [2022091110       3821          0          1]\n",
      " [2022091102       3652          0          1]]\n",
      "Input shape: (64, 100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (64, 46) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.3415     0.5729831  0.33166668 ... 0.53283304 0.39650002 0.5613508 ]\n",
      " [0.3425     0.572045   0.3325     ... 0.5318949  0.39650002 0.5613508 ]\n",
      " [0.34341666 0.571107   0.33333334 ... 0.53001875 0.39650002 0.5613508 ]]\n",
      "Target values (first 5): [[0.34891668 0.5667918  0.33875    0.37204504 0.33783334 0.52345216\n",
      "  0.36725    0.36604127 0.37441668 0.50337714 0.3755     0.5581614\n",
      "  0.3635     0.67673546 0.37241668 0.5825516  0.357      0.42532834\n",
      "  0.374      0.615197   0.37025    0.53827393 0.41308334 0.53320825\n",
      "  0.4265     0.543152   0.40933332 0.5523452  0.40833333 0.59287053\n",
      "  0.4155     0.5570356  0.40533334 0.5369606  0.41875    0.560788\n",
      "  0.41975    0.6065666  0.403      0.55909944 0.434      0.57767355\n",
      "  0.42341667 0.50450283 0.39658335 0.5613508 ]\n",
      " [0.29766667 0.5673546  0.30341667 0.5956848  0.438      0.7249531\n",
      "  0.356      0.92026263 0.36516666 0.62908065 0.29166666 0.49624765\n",
      "  0.276      0.55478424 0.24983333 0.58536583 0.41416666 0.36341465\n",
      "  0.32025    0.269606   0.31408334 0.5424015  0.2505     0.5478424\n",
      "  0.30966666 0.5628518  0.34025    0.54108816 0.33358333 0.5444653\n",
      "  0.5053333  0.63433397 0.44075    0.72851783 0.376      0.3902439\n",
      "  0.425      0.39849907 0.40016666 0.6641651  0.32216668 0.48949343\n",
      "  0.40675    0.8444653  0.43800002 0.7178236 ]\n",
      " [0.63625    0.47429642 0.5024167  0.23639774 0.54483336 0.42345217\n",
      "  0.60758334 0.50712943 0.5750833  0.6968105  0.5024167  0.37354597\n",
      "  0.61441666 0.5902439  0.65541667 0.54615384 0.62408334 0.57673544\n",
      "  0.50375    0.74784243 0.6220833  0.49512196 0.614      0.50300187\n",
      "  0.632      0.4684803  0.45166665 0.23095685 0.463      0.78874296\n",
      "  0.38683334 0.46172607 0.524      0.7290807  0.49283335 0.4752345\n",
      "  0.61808336 0.5771107  0.45291665 0.6195122  0.61125    0.5667918\n",
      "  0.5039167  0.32401502 0.652      0.54183865]\n",
      " [0.76316667 0.58517826 0.76241666 0.36697936 0.717      0.5598499\n",
      "  0.7600833  0.6309568  0.76708335 0.55909944 0.7633333  0.50581616\n",
      "  0.75666666 0.5592871  0.7611667  0.60600376 0.74725    0.6335835\n",
      "  0.76316667 0.5315197  0.73425    0.5587242  0.79175    0.65666044\n",
      "  0.86116666 0.49849907 0.7825     0.5356473  0.81991667 0.75797373\n",
      "  0.8045     0.584803   0.80341667 0.31688556 0.78125    0.50881803\n",
      "  0.77758336 0.57016885 0.8055     0.5467167  0.77933335 0.59380865\n",
      "  0.7884167  0.4628518  0.76991665 0.5577861 ]\n",
      " [0.27083334 0.5208255  0.29658332 0.56228894 0.26166666 0.5836773\n",
      "  0.27316666 0.6170732  0.22091667 0.6729831  0.27583334 0.67467165\n",
      "  0.2395     0.16266416 0.22275    0.33452156 0.23391667 0.745591\n",
      "  0.2645     0.5506567  0.26283333 0.6170732  0.14658333 0.48742965\n",
      "  0.26441666 0.63189495 0.1645     0.63339585 0.26908332 0.47129455\n",
      "  0.2545     0.51988745 0.259      0.6005629  0.1975     0.7628518\n",
      "  0.26425    0.5664165  0.26316667 0.6797373  0.184      0.3467167\n",
      "  0.22691667 0.17429644 0.29816666 0.5664165 ]]\n",
      "\n",
      "Example 3:\n",
      "Metadata tensor: tf.Tensor(\n",
      "[[2022091112       1613          0         62]\n",
      " [2022091806       2905          0         26]\n",
      " [2022091102       3652          0          1]\n",
      " [2022091104       3754          0         11]\n",
      " [2022091104       4372          0         73]\n",
      " [2022091102        942          0          1]\n",
      " [2022091806       2905          0          1]\n",
      " [2022091500       3090          0         89]\n",
      " [2022091112       1613          0          1]\n",
      " [2022091901       1290          0         18]\n",
      " [2022091110       1232          0          1]\n",
      " [2022091110       1290          0         48]\n",
      " [2022091901       3088          0          1]\n",
      " [2022091901       3088          0          1]\n",
      " [2022091806       3030          0         18]\n",
      " [2022091104       3754          0          5]\n",
      " [2022091806       2905          0         32]\n",
      " [2022091104       4372          0          1]\n",
      " [2022091805       2634          0         37]\n",
      " [2022091901       1290          0          1]\n",
      " [2022091110       1539          0         58]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091808       2622          0          1]\n",
      " [2022091112       1613          0         65]\n",
      " [2022091112       2886          0         63]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091801        218          0         34]\n",
      " [2022091806       2905          0         22]\n",
      " [2022091110       1290          0          1]\n",
      " [2022091110       1290          0          1]\n",
      " [2022090800        646          0          1]\n",
      " [2022091500        257          0          1]\n",
      " [2022091812       3347          0          1]\n",
      " [2022091801        218          0          1]\n",
      " [2022091804       3308          0          1]\n",
      " [2022091500        257          0          1]\n",
      " [2022091500       3090          0          1]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091110       1539          0          1]\n",
      " [2022091806       3030          0          1]\n",
      " [2022091500        257          0          9]\n",
      " [2022091104       3754          0          1]\n",
      " [2022091112       1613          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091811        835          0         47]\n",
      " [2022091102       3652          0          1]\n",
      " [2022091110       1232          0         11]\n",
      " [2022091102        942          0          1]\n",
      " [2022091901       1290          0         55]\n",
      " [2022091500       3090          0         56]\n",
      " [2022091808        631          0         21]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091102        942          0          1]\n",
      " [2022091805       2634          0          1]\n",
      " [2022091805       2634          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091104       4372          0         37]\n",
      " [2022091112       1613          0         52]\n",
      " [2022091112       2886          0        101]\n",
      " [2022091800       2682          0          1]\n",
      " [2022091110       1232          0         19]\n",
      " [2022091808        631          0          1]\n",
      " [2022091110       1232          0         20]\n",
      " [2022091806       2905          0          1]], shape=(64, 4), dtype=int32)\n",
      "Metadata values: [[2022091112       1613          0         62]\n",
      " [2022091806       2905          0         26]\n",
      " [2022091102       3652          0          1]\n",
      " [2022091104       3754          0         11]\n",
      " [2022091104       4372          0         73]\n",
      " [2022091102        942          0          1]\n",
      " [2022091806       2905          0          1]\n",
      " [2022091500       3090          0         89]\n",
      " [2022091112       1613          0          1]\n",
      " [2022091901       1290          0         18]\n",
      " [2022091110       1232          0          1]\n",
      " [2022091110       1290          0         48]\n",
      " [2022091901       3088          0          1]\n",
      " [2022091901       3088          0          1]\n",
      " [2022091806       3030          0         18]\n",
      " [2022091104       3754          0          5]\n",
      " [2022091806       2905          0         32]\n",
      " [2022091104       4372          0          1]\n",
      " [2022091805       2634          0         37]\n",
      " [2022091901       1290          0          1]\n",
      " [2022091110       1539          0         58]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091808       2622          0          1]\n",
      " [2022091112       1613          0         65]\n",
      " [2022091112       2886          0         63]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091801        218          0         34]\n",
      " [2022091806       2905          0         22]\n",
      " [2022091110       1290          0          1]\n",
      " [2022091110       1290          0          1]\n",
      " [2022090800        646          0          1]\n",
      " [2022091500        257          0          1]\n",
      " [2022091812       3347          0          1]\n",
      " [2022091801        218          0          1]\n",
      " [2022091804       3308          0          1]\n",
      " [2022091500        257          0          1]\n",
      " [2022091500       3090          0          1]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091110       1539          0          1]\n",
      " [2022091806       3030          0          1]\n",
      " [2022091500        257          0          9]\n",
      " [2022091104       3754          0          1]\n",
      " [2022091112       1613          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091811        835          0         47]\n",
      " [2022091102       3652          0          1]\n",
      " [2022091110       1232          0         11]\n",
      " [2022091102        942          0          1]\n",
      " [2022091901       1290          0         55]\n",
      " [2022091500       3090          0         56]\n",
      " [2022091808        631          0         21]\n",
      " [2022091500       2046          0          1]\n",
      " [2022091102        942          0          1]\n",
      " [2022091805       2634          0          1]\n",
      " [2022091805       2634          0          1]\n",
      " [2022091811        835          0          1]\n",
      " [2022091104       4372          0         37]\n",
      " [2022091112       1613          0         52]\n",
      " [2022091112       2886          0        101]\n",
      " [2022091800       2682          0          1]\n",
      " [2022091110       1232          0         19]\n",
      " [2022091808        631          0          1]\n",
      " [2022091110       1232          0         20]\n",
      " [2022091806       2905          0          1]]\n",
      "Input shape: (64, 100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (64, 46) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [[0.39608333 0.44596624 0.40808332 ... 0.57373357 0.38366666 0.44859287]\n",
      " [0.39608333 0.44596624 0.40725    ... 0.57335836 0.38366666 0.44859287]\n",
      " [0.39616665 0.4457786  0.40641665 ... 0.5729831  0.38366666 0.44840524]\n",
      " ...\n",
      " [0.43225    0.43733585 0.35641667 ... 0.5446529  0.43458334 0.43489683]\n",
      " [0.43583333 0.4380863  0.35125    ... 0.5437148  0.43800002 0.436773  ]\n",
      " [0.43925    0.439212   0.346      ... 0.5425891  0.44116667 0.43883675]]\n",
      "Target values (first 5): [[0.45483333 0.44727954 0.31283334 0.5555347  0.43108332 0.524015\n",
      "  0.39691666 0.4510319  0.37458333 0.3716698  0.40083334 0.42195123\n",
      "  0.30175    0.32833022 0.41733333 0.38405254 0.29066667 0.73752344\n",
      "  0.42208335 0.34821764 0.40041667 0.4988743  0.42533332 0.32964352\n",
      "  0.1875     0.5183865  0.41075    0.37973735 0.34775    0.41163227\n",
      "  0.39158332 0.46003753 0.31325    0.5688555  0.25741667 0.2902439\n",
      "  0.32466668 0.2836773  0.26591668 0.7307692  0.32591668 0.5694184\n",
      "  0.434      0.5307692  0.45508334 0.44878048]\n",
      " [0.18016666 0.51894933 0.16366667 0.36228892 0.15025    0.3673546\n",
      "  0.16875    0.308818   0.10583334 0.09437148 0.12658334 0.56622887\n",
      "  0.13225    0.2945591  0.15775    0.37335834 0.15783334 0.2793621\n",
      "  0.12166667 0.73245776 0.15008333 0.38255158 0.12558334 0.3425891\n",
      "  0.13866666 0.3682927  0.12575    0.44934335 0.163      0.34727955\n",
      "  0.10075    0.09962477 0.14958334 0.29943714 0.15608333 0.36679175\n",
      "  0.13275    0.32814258 0.16183333 0.37636024 0.10741667 0.53395873\n",
      "  0.089      0.7510319  0.14641666 0.37842402]\n",
      " [0.23766667 0.4825516  0.23625    0.54934335 0.23883334 0.5031895\n",
      "  0.24708334 0.43527204 0.24066667 0.40469044 0.1845     0.4425891\n",
      "  0.24316667 0.2185741  0.23316666 0.52420264 0.23925    0.44052532\n",
      "  0.24191667 0.45741087 0.24316667 0.42213884 0.24733333 0.5056285\n",
      "  0.24958333 0.4228893  0.27766666 0.5510319  0.24966666 0.3727955\n",
      "  0.26291665 0.46060038 0.27308333 0.5099437  0.2485     0.4628518\n",
      "  0.27133334 0.42363977 0.25083333 0.58517826 0.25866666 0.22045028\n",
      "  0.36116666 0.38536584 0.24216667 0.44165105]\n",
      " [0.5675833  0.4435272  0.5599167  0.38855535 0.55625    0.29155722\n",
      "  0.55333334 0.44634145 0.5556667  0.58536583 0.57516664 0.39099437\n",
      "  0.6085     0.44202626 0.55841666 0.4163227  0.55733335 0.47579738\n",
      "  0.56025    0.50168854 0.56408334 0.5467167  0.54225    0.4934334\n",
      "  0.48216668 0.6108818  0.49066666 0.27973732 0.54333335 0.41707316\n",
      "  0.5434167  0.5369606  0.5150833  0.39380863 0.51925    0.5643527\n",
      "  0.54333335 0.34202626 0.46966666 0.37579736 0.47925    0.5260788\n",
      "  0.51533335 0.45797375 0.5485833  0.44634148]\n",
      " [0.5236667  0.4652908  0.5488333  0.5814259  0.47558334 0.50018764\n",
      "  0.5065     0.5846154  0.5118333  0.31181988 0.5254167  0.18405253\n",
      "  0.5010833  0.530394   0.42975    0.57016885 0.5111667  0.37729833\n",
      "  0.54216665 0.20450282 0.49758333 0.41369605 0.491      0.52532834\n",
      "  0.51566666 0.42551595 0.52533334 0.17204502 0.55158335 0.17560975\n",
      "  0.54525    0.52307695 0.5416667  0.26022515 0.5085833  0.2129456\n",
      "  0.5276667  0.2163227  0.53966665 0.29587242 0.557      0.23714821\n",
      "  0.48791668 0.39061913 0.5261667  0.18442777]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 19:22:18.821016: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Examine first 3 examples\n",
    "print(\"\\nFirst 3 examples:\")\n",
    "for i, example in enumerate(train_ds.take(3)):\n",
    "    # Each example contains 3 components:\n",
    "    meta_tensor = example[0]  # Metadata (gameId, playId, split_id, firstFrameId)\n",
    "    x_tensor = example[1]     # Input sequence (padded frames)\n",
    "    y_tensor = example[2]     # Target vector\n",
    "    \n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(\"Metadata tensor:\", meta_tensor)\n",
    "    print(f\"Metadata values: {meta_tensor.numpy()}\")\n",
    "    print(f\"Input shape: {x_tensor.shape} | dtype: {x_tensor.dtype}\")\n",
    "    print(f\"Target shape: {y_tensor.shape} | dtype: {y_tensor.dtype}\")\n",
    "    \n",
    "    # First 5 elements of first frame's features\n",
    "    print(\"First frame features (first 5 values):\", x_tensor[0, :-5].numpy())\n",
    "    print(\"Target values (first 5):\", y_tensor[:5].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "117a222c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cardinality: 592871\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset cardinality:\",\n",
    "      tf.data.experimental.cardinality(raw_ds).numpy())   # should now print a number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6089c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: (64, 100, 46)\n",
      "y_batch shape: (64, 46)\n",
      "x_batch shape: (64, 100, 46)\n",
      "y_batch shape: (64, 46)\n",
      "x_batch shape: (64, 100, 46)\n",
      "y_batch shape: (64, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 19:22:23.005823: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "def drop_meta(meta, x, y):\n",
    "    return x, y\n",
    "\n",
    "train_ds = (raw_ds\n",
    "            .filter(filter_split(0))\n",
    "            .map(drop_meta, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .shuffle(4096)\n",
    "            .batch(64)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "val_ds   = (raw_ds\n",
    "            .filter(filter_split(1))\n",
    "            .map(drop_meta, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(64)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "test_ds  = (raw_ds\n",
    "            .filter(filter_split(2))\n",
    "            .map(drop_meta, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(64)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "# Take one batch from the dataset\n",
    "for x_batch, y_batch in train_ds.take(1):\n",
    "    print(\"x_batch shape:\", x_batch.shape)\n",
    "    print(\"y_batch shape:\", y_batch.shape)\n",
    "\n",
    "for x_batch, y_batch in val_ds.take(1):\n",
    "    print(\"x_batch shape:\", x_batch.shape)\n",
    "    print(\"y_batch shape:\", y_batch.shape)\n",
    "\n",
    "for x_batch, y_batch in test_ds.take(1):\n",
    "    print(\"x_batch shape:\", x_batch.shape)\n",
    "    print(\"y_batch shape:\", y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e47797cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset element specification: (TensorSpec(shape=(4,), dtype=tf.int32, name=None), TensorSpec(shape=(100, 46), dtype=tf.float32, name=None), TensorSpec(shape=(46,), dtype=tf.float32, name=None))\n",
      "\n",
      "First 3 examples:\n",
      "\n",
      "Example 1:\n",
      "Metadata tensor: tf.Tensor([2022091109       2481          2          1], shape=(4,), dtype=int32)\n",
      "Metadata values: [2022091109       2481          2          1]\n",
      "Input shape: (100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (46,) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [0. 0. 0. 0. 0.]\n",
      "Target values (first 5): [0.14491667 0.6643527  0.14858334 0.30731708 0.12266666]\n",
      "\n",
      "Example 2:\n",
      "Metadata tensor: tf.Tensor([2022091109       2481          2          1], shape=(4,), dtype=int32)\n",
      "Metadata values: [2022091109       2481          2          1]\n",
      "Input shape: (100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (46,) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [0. 0. 0. 0. 0.]\n",
      "Target values (first 5): [0.14316666 0.6733583  0.14766666 0.30450282 0.12191667]\n",
      "\n",
      "Example 3:\n",
      "Metadata tensor: tf.Tensor([2022091109       2481          2          1], shape=(4,), dtype=int32)\n",
      "Metadata values: [2022091109       2481          2          1]\n",
      "Input shape: (100, 46) | dtype: <dtype: 'float32'>\n",
      "Target shape: (46,) | dtype: <dtype: 'float32'>\n",
      "First frame features (first 5 values): [0. 0. 0. 0. 0.]\n",
      "Target values (first 5): [0.14141667 0.68217635 0.14675    0.3018762  0.12116667]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../processed_data/transformer_dataset\"\n",
    "\n",
    "# Load dataset without any transformations\n",
    "raw_ds = tf.data.Dataset.load(dataset_path)\n",
    "\n",
    "# Print dataset structure\n",
    "print(\"Dataset element specification:\", raw_ds.element_spec)\n",
    "\n",
    "# Examine first 3 examples\n",
    "print(\"\\nFirst 3 examples:\")\n",
    "for i, example in enumerate(raw_ds.take(3)):\n",
    "    # Each example contains 3 components:\n",
    "    meta_tensor = example[0]  # Metadata (gameId, playId, split_id, firstFrameId)\n",
    "    x_tensor = example[1]     # Input sequence (padded frames)\n",
    "    y_tensor = example[2]     # Target vector\n",
    "    \n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(\"Metadata tensor:\", meta_tensor)\n",
    "    print(f\"Metadata values: {meta_tensor.numpy()}\")\n",
    "    print(f\"Input shape: {x_tensor.shape} | dtype: {x_tensor.dtype}\")\n",
    "    print(f\"Target shape: {y_tensor.shape} | dtype: {y_tensor.dtype}\")\n",
    "    \n",
    "    # First 5 elements of first frame's features\n",
    "    print(\"First frame features (first 5 values):\", x_tensor[0, :5].numpy())\n",
    "    print(\"Target values (first 5):\", y_tensor[:5].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b50d2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "NUM_FEATS = 46          # x,y for 23 entities\n",
    "MAX_LEN  = 100          # same value you used in dataset builder\n",
    "D_MODEL  = 128          # transformer hidden size\n",
    "N_HEADS  = 4\n",
    "N_LAYERS = 4\n",
    "D_FF     = 512\n",
    "DROPOUT  = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a069e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔═══════════════════╗\n",
    "# ║ 2. Positional enc ║  (learnable 1‑D embedding)\n",
    "# ╚═══════════════════╝\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super().__init__()\n",
    "        self.pos_emb = self.add_weight(\n",
    "            name=\"pos_emb\",\n",
    "            shape=(max_len, d_model),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.pos_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1372b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔═══════════════════════════╗\n",
    "# ║ 3. Padding‑mask function  ║\n",
    "# ╚═══════════════════════════╝\n",
    "class PaddingMask(layers.Layer):\n",
    "    def call(self, x):\n",
    "        # x:  (B, T, F) — zero‐padded on the left\n",
    "        pad = tf.reduce_all(tf.equal(x, 0.0), axis=-1)      # → (B, T)\n",
    "        # reshape to (B, 1, 1, T) for MultiHeadAttention\n",
    "        return pad[:, tf.newaxis, tf.newaxis, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e0ec51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔════════════════════════╗\n",
    "# ║ 4. Transformer encoder ║\n",
    "# ╚════════════════════════╝\n",
    "def transformer_block(d_model, n_heads, d_ff, dropout):\n",
    "    inputs   = layers.Input(shape=(None, d_model))\n",
    "    padding  = layers.Input(shape=(1,1,None), dtype=tf.bool)  # mask\n",
    "\n",
    "    x = layers.MultiHeadAttention(\n",
    "        num_heads=n_heads, key_dim=d_model//n_heads, dropout=dropout\n",
    "    )(inputs, inputs, attention_mask=padding)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs + x)\n",
    "\n",
    "    y = layers.Dense(d_ff, activation=\"relu\")(x)\n",
    "    y = layers.Dense(d_model)(y)\n",
    "    y = layers.Dropout(dropout)(y)\n",
    "    y = layers.LayerNormalization(epsilon=1e-6)(x + y)\n",
    "\n",
    "    return keras.Model([inputs, padding], y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22063c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"NFL_Frame_Predictor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"NFL_Frame_Predictor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sequence            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cast (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,016</span> │ cast[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cast_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encoding │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,800</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncodin…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ padding_mask        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cast_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PaddingMask</span>)       │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ positional_encod… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ functional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ functional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cast_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pred_xy (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │ cast_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sequence            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m46\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cast (\u001b[38;5;33mCast\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m46\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ sequence[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │      \u001b[38;5;34m6,016\u001b[0m │ cast[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cast_1 (\u001b[38;5;33mCast\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m46\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ sequence[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encoding │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m12,800\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mPositionalEncodin…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ padding_mask        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ cast_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mPaddingMask\u001b[0m)       │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m198,272\u001b[0m │ positional_encod… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m198,272\u001b[0m │ functional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m198,272\u001b[0m │ functional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m198,272\u001b[0m │ functional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ functional_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cast_10 (\u001b[38;5;33mCast\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pred_xy (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)        │      \u001b[38;5;34m5,934\u001b[0m │ cast_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">817,838</span> (3.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m817,838\u001b[0m (3.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">817,838</span> (3.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m817,838\u001b[0m (3.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ╔════════════════════════════════╗\n",
    "# ║ 5. End‑to‑end prediction model ║\n",
    "# ╚════════════════════════════════╝\n",
    "def build_model(\n",
    "    num_feats=NUM_FEATS,\n",
    "    max_len=MAX_LEN,\n",
    "    d_model=D_MODEL,\n",
    "    n_heads=N_HEADS,\n",
    "    n_layers=N_LAYERS,\n",
    "    d_ff=D_FF,\n",
    "    dropout=DROPOUT,\n",
    "):\n",
    "    seq_in  = layers.Input(shape=(max_len, num_feats), name=\"sequence\")   # (B,T,F)\n",
    "\n",
    "    # Linear projection to d_model\n",
    "    x = layers.Dense(d_model)(seq_in)\n",
    "\n",
    "    # Add learnable positional encodings\n",
    "    x = PositionalEncoding(max_len, d_model)(x)\n",
    "\n",
    "    # Build padding mask once\n",
    "    pad_mask = PaddingMask()(seq_in)\n",
    "\n",
    "    # Stack encoder layers\n",
    "    for _ in range(n_layers):\n",
    "        x = transformer_block(d_model, n_heads, d_ff, dropout)([x, pad_mask])\n",
    "\n",
    "    # We need the hidden state that corresponds to *frame t* (the last row)\n",
    "    # – that is always index -1 thanks to left padding.\n",
    "    h_t = layers.Lambda(lambda t: t[:, -1])(x)          # (B, D)\n",
    "\n",
    "    # Regress the 46 co‑ordinates\n",
    "    # out = layers.Dense(num_feats, name=\"pred_xy\")(h_t)\n",
    "    out = layers.Dense(num_feats, dtype='float32', name=\"pred_xy\")(h_t) # This is important for mixed precision (training on GPU)\n",
    "\n",
    "\n",
    "    return keras.Model(seq_in, out, name=\"NFL_Frame_Predictor\")\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60621355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745605351.544888   64817 service.cc:148] XLA service 0x7f33600087a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745605351.544925   64817 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-04-25 19:22:31.689220: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1745605352.502585   64817 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-04-25 19:22:34.091910: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6_0', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "2025-04-25 19:22:36.727296: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_29', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "2025-04-25 19:22:37.231173: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_29', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "I0000 00:00:1745605364.373934   64817 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6988/Unknown \u001b[1m310s\u001b[0m 41ms/step - loss: 0.0307 - mean_absolute_error: 0.1030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 19:27:35.763751: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:36.432894: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:36.576041: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:37.230365: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_27', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6993/Unknown \u001b[1m320s\u001b[0m 43ms/step - loss: 0.0306 - mean_absolute_error: 0.1030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 19:27:43.979597: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "/home/juanbsosa/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "2025-04-25 19:27:45.520918: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 132 bytes spill stores, 132 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:45.595243: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:45.653770: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 20 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:45.755176: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:45.785764: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:46.064033: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:46.278533: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:46.299319: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6_0', 268 bytes spill stores, 412 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:46.333977: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:46.347778: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-25 19:27:46.463610: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4', 20 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:19.295157: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:19.419849: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:19.475245: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 132 bytes spill stores, 132 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:19.477058: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:19.604382: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:19.924404: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:19.972959: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:20.138471: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4', 20 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:20.242792: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:20.267475: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:20.399620: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:20.477119: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6_0', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:20.542411: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:20.555899: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 20 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2025-04-25 19:32:20.561990: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m599s\u001b[0m 83ms/step - loss: 0.0306 - mean_absolute_error: 0.1030 - val_loss: 4.6110e-04 - val_mean_absolute_error: 0.0164\n",
      "Epoch 2/15\n",
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 79ms/step - loss: 7.1819e-04 - mean_absolute_error: 0.0204 - val_loss: 2.7995e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 3/15\n",
      "\u001b[1m6989/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.3174e-04 - mean_absolute_error: 0.0139"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 19:46:25.558464: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2025-04-25 19:50:46.827922: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 19:50:46.827971: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 78ms/step - loss: 3.3171e-04 - mean_absolute_error: 0.0139 - val_loss: 1.4931e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 4/15\n",
      "\u001b[1m6991/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.0942e-04 - mean_absolute_error: 0.0111"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 19:59:55.283049: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 19:59:55.283103: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 78ms/step - loss: 2.0942e-04 - mean_absolute_error: 0.0111 - val_loss: 9.7101e-05 - val_mean_absolute_error: 0.0080\n",
      "Epoch 5/15\n",
      "\u001b[1m6991/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.5119e-04 - mean_absolute_error: 0.0094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 20:09:07.717425: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 20:09:07.717476: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 79ms/step - loss: 1.5119e-04 - mean_absolute_error: 0.0094 - val_loss: 7.4390e-05 - val_mean_absolute_error: 0.0070\n",
      "Epoch 6/15\n",
      "\u001b[1m6992/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.1485e-04 - mean_absolute_error: 0.0082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 20:18:19.043498: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 20:18:19.043545: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 78ms/step - loss: 1.1485e-04 - mean_absolute_error: 0.0082 - val_loss: 4.4977e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 7/15\n",
      "\u001b[1m6989/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 8.8897e-05 - mean_absolute_error: 0.0072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 20:23:06.690234: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2025-04-25 20:27:29.537339: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 20:27:29.537390: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 78ms/step - loss: 8.8893e-05 - mean_absolute_error: 0.0072 - val_loss: 4.6056e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 8/15\n",
      "\u001b[1m6992/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 7.1375e-05 - mean_absolute_error: 0.0064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 20:36:39.733588: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 20:36:39.733646: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 78ms/step - loss: 7.1373e-05 - mean_absolute_error: 0.0064 - val_loss: 2.5112e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 9/15\n",
      "\u001b[1m6992/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.7577e-05 - mean_absolute_error: 0.0058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 20:45:49.173566: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 20:45:49.173611: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 78ms/step - loss: 5.7576e-05 - mean_absolute_error: 0.0058 - val_loss: 5.8776e-05 - val_mean_absolute_error: 0.0060\n",
      "Epoch 10/15\n",
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 78ms/step - loss: 4.7977e-05 - mean_absolute_error: 0.0053 - val_loss: 2.1763e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 11/15\n",
      "\u001b[1m6990/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 4.0617e-05 - mean_absolute_error: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 21:04:09.422619: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 21:04:09.422669: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 78ms/step - loss: 4.0616e-05 - mean_absolute_error: 0.0048 - val_loss: 2.1151e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 12/15\n",
      "\u001b[1m6990/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.5393e-05 - mean_absolute_error: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 21:13:18.355136: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 21:13:18.355180: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 78ms/step - loss: 3.5393e-05 - mean_absolute_error: 0.0045 - val_loss: 1.7882e-05 - val_mean_absolute_error: 0.0030\n",
      "Epoch 13/15\n",
      "\u001b[1m6988/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.0409e-05 - mean_absolute_error: 0.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 21:22:28.258838: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 21:22:28.258887: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 78ms/step - loss: 3.0409e-05 - mean_absolute_error: 0.0042 - val_loss: 1.9668e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 14/15\n",
      "\u001b[1m6990/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.7861e-05 - mean_absolute_error: 0.0040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 21:31:42.861701: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 21:31:42.861773: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 79ms/step - loss: 2.7860e-05 - mean_absolute_error: 0.0040 - val_loss: 2.2100e-05 - val_mean_absolute_error: 0.0035\n",
      "Epoch 15/15\n",
      "\u001b[1m6989/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.4660e-05 - mean_absolute_error: 0.0038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 21:36:29.968585: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2025-04-25 21:40:53.349280: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 21:40:53.349321: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6993/6993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 78ms/step - loss: 2.4660e-05 - mean_absolute_error: 0.0038 - val_loss: 1.9976e-05 - val_mean_absolute_error: 0.0033\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m1405/1405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 190ms/step - loss: 1.6967e-05 - mean_absolute_error: 0.0030\n",
      "\n",
      "✅  Test MSE: 0.00002   |   Test MAE: 0.00303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 21:45:20.278538: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 761195700543843345\n",
      "2025-04-25 21:45:20.278579: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14578956645690315843\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ╔════════════════════╗\n",
    "# ║ 6. Compile & train ║\n",
    "# ╚════════════════════╝\n",
    "\n",
    "# ── 1)  Make sure we have a place to put checkpoints ─────────────────\n",
    "WEIGHT_DIR = Path(\"../weights\")\n",
    "WEIGHT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=(WEIGHT_DIR /\n",
    "            #   \"epoch_{epoch:03d}-val{val_loss:.4f}.keras\").as_posix(),\n",
    "              \"epoch_{epoch:03d}-val{val_loss:.4f}.weights.h5\").as_posix(),\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=False,      # save every epoch → “periodic” archive\n",
    "    save_weights_only=True,    # just the weights, not optimizer state\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# ── 2)  Early-stopping ───────────────────────────────────────────────\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# ── 3)  Compile the model ────────────────────────────────────────────\n",
    "LR = 1e-4\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(LR),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    ")\n",
    "\n",
    "# ── 4)  Fit – stop early, save weights each epoch ────────────────────\n",
    "EPOCHS = 15   # high ceiling; early-stop decides real count\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stop, ckpt_cb],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# optional: evaluate on test set after training\n",
    "test_loss, test_mae = model.evaluate(test_ds, verbose=1)\n",
    "print(f\"\\n✅  Test MSE: {test_loss:.5f}   |   Test MAE: {test_mae:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcdd029f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 21:45:20.741125: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE (batch): 4.876001e-06\n"
     ]
    }
   ],
   "source": [
    "# ╔═══════════════╗\n",
    "# ║ 7. Evaluation ║\n",
    "# ╚═══════════════╝\n",
    "# Simple end‑to‑end evaluation on a held‑out batch\n",
    "for X_batch, y_batch in val_ds.take(1):\n",
    "    y_pred = model(X_batch)\n",
    "    mse = tf.reduce_mean(tf.square(y_pred - y_batch))\n",
    "    print(\"Validation MSE (batch):\", mse.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4217eb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ╔════════════════╗\n",
    "# ║ 8. Curves Plot ║\n",
    "# ╚════════════════╝\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.title('Loss curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
